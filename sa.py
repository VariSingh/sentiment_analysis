import nltk
from nltk.tokenize import word_tokenize

sentense = "This is a sample sentense"
tokens = nltk.word_tokenize(sentense)
print(tokens)
